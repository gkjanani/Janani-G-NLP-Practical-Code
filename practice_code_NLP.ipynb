{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjKVlXzEnh2A",
        "outputId": "473e4345-4618-4d54-f280-17189b235f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "yuI5vH4pnpiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "word = \"meeting\"\n",
        "lema = lemmatizer.lemmatize(word)\n",
        "print(f\"lemmatized word:{lema}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THGb3xM-nvoa",
        "outputId": "6c7f451d-c9e0-441c-bced-c5dfbf73e9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmatized word:meeting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt7jNvrAn_l_",
        "outputId": "d3f2386b-027c-493c-840a-eaf14384b6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "mimPRu23oCST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"flew\"\n",
        "lema = lemmatizer.lemmatize(word)\n",
        "print(f\"lemmatized word:{lema}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfJr-FE6oHHj",
        "outputId": "d6709a51-82f8-4997-8fba-92604e244aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmatized word:flew\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_OCtzXNoTWt",
        "outputId": "efafd607-5a48-464c-926d-ddb9cd4a0a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "T6gYBmt0oTzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"drawing\"\n",
        "lema = lemmatizer.lemmatize(word)\n",
        "print(f\"lemmatized word:{lema}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6wZfD8GpStn",
        "outputId": "5a5872bd-40dd-4c69-ebdc-829aa560ae20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmatized word:drawing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No_AB_kepRyy",
        "outputId": "4574b6a3-e5a5-4274-cb1e-0346597eb6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "Y3cr37IgpSNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"ran\"\n",
        "lema = lemmatizer.lemmatize(word)\n",
        "print(f\"lemmatized word:{lema}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKKNmZSrp1p1",
        "outputId": "7f8421fa-21b9-4db8-9ba9-f9e353255bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmatized word:ran\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIEc304qp2Ii",
        "outputId": "85b270f9-aeca-46b9-d89e-8449dc554e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "w_s6K3-zqTSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"drwan\"\n",
        "lema = lemmatizer.lemmatize(word)\n",
        "print(f\"lemmatized word:{lema}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoTDlPO-qUFO",
        "outputId": "c4a3c333-dd42-4d13-f008-427b0406a5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmatized word:drwan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wordnet_ic\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "5Q4WbrZSqUh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "sentence = \"The dogs are running\"\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "tokens = word_tokenize(sentence)\n",
        "tagged = pos_tag(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8wsCMSyqoEP",
        "outputId": "168651e6-6513-40d3-fa1c-2334dfdfd7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_word = [lemmatizer.lemmatize(word, pos='v' if tag.startswith('v')else'n') for word, tag in tagged]"
      ],
      "metadata": {
        "id": "Ss2NRnBaqopi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wordnet_ic\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "HMK-93eirGr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "sentence = \"I am studying books\"\n",
        "tokens = word_tokenize(sentence)\n",
        "tagged = pos_tag(tokens)"
      ],
      "metadata": {
        "id": "EUj6FeonrGUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_word = [lemmatizer.lemmatize(word, pos='v' if tag.startswith('v')else'n') for word, tag in tagged]"
      ],
      "metadata": {
        "id": "RExcUt6UrUtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxiagE9UfD6j",
        "outputId": "4f44cc1e-2fc2-4cd5-e74c-bb38f59cee35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"NLTK is a powerful library for natural language processing.\"\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "sBkVNbDOfD3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = pos_tag(words)"
      ],
      "metadata": {
        "id": "gy_wtgv-fSXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Taxt:\")\n",
        "print(text)\n",
        "\n",
        "print(\"\\nPOS Tagging Result:\")\n",
        "for word, pos_tags in pos_tags:\n",
        "    print(f\"{word}: {pos_tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foEcIq-MfSLP",
        "outputId": "c7f819ea-3d04-4794-f6b8-6e703cde1b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Taxt:\n",
            "NLTK is a powerful library for natural language processing.\n",
            "\n",
            "POS Tagging Result:\n",
            "NLTK: NNP\n",
            "is: VBZ\n",
            "a: DT\n",
            "powerful: JJ\n",
            "library: NN\n",
            "for: IN\n",
            "natural: JJ\n",
            "language: NN\n",
            "processing: NN\n",
            ".: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The quick brown for jumps over the lazy dog.\"\n",
        "words = word_tokenize(text)\n",
        "\n",
        "pos_tags = pos_tag(words)\n",
        "\n",
        "print(\"Original Taxt:\")\n",
        "print(text)\n",
        "\n",
        "print(\"\\nPOS Tagging Result:\")\n",
        "for word, pos_tags in pos_tags:\n",
        "    print(f\"{word}: {pos_tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAMsN0o7fYtE",
        "outputId": "e9c1a717-4829-4e2e-ea1b-0d63f0c8198f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Taxt:\n",
            "The quick brown for jumps over the lazy dog.\n",
            "\n",
            "POS Tagging Result:\n",
            "The: DT\n",
            "quick: JJ\n",
            "brown: NN\n",
            "for: IN\n",
            "jumps: NNS\n",
            "over: IN\n",
            "the: DT\n",
            "lazy: JJ\n",
            "dog: NN\n",
            ".: .\n"
          ]
        }
      ]
    }
  ]
}